{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2938918b-ec01-4ef9-a0e2-e018038d2965",
   "metadata": {},
   "source": [
    "# Project 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ce3b18-c0f4-40a5-991d-f08c5f48f851",
   "metadata": {},
   "source": [
    "#### Jason Kim \n",
    "#### Braulio Lopez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729fbe8-e7e4-4608-9f91-654aca7fa9ad",
   "metadata": {},
   "source": [
    "### Part 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66736b9-cd39-4a22-b85a-25e5d1cba3d2",
   "metadata": {},
   "source": [
    "#### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4e1004-3a64-45ce-811e-56df55181d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.4-py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m230.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m252.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting etils[enp,epath,etree]>=0.9.0\n",
      "  Downloading etils-1.8.0-py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.1/156.1 kB\u001b[0m \u001b[31m256.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (1.26.3)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (4.23.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (5.9.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.31.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.4.0)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m260.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Collecting array-record>=0.5.0\n",
      "  Downloading array_record-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m227.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m306.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting importlib_resources\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.9.0)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2023.11.17)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m298.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m313.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.20\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m299.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21483 sha256=435b66dea9abfafcaeaf67d6e9a677a417abb832521649be4c7105e70d5c7e03\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ev4ptsdj/wheels/74/05/89/d0909dd6ebad0a26f2b4dcb2499b1d65999c5b6ed416be7f85\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, tqdm, toml, protobuf, promise, importlib_resources, fsspec, etils, click, absl-py, googleapis-common-protos, tensorflow-metadata, array-record, tensorflow_datasets\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tfds is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 array-record-0.5.1 click-8.1.7 dm-tree-0.1.8 etils-1.8.0 fsspec-2024.3.1 googleapis-common-protos-1.63.0 importlib_resources-6.4.0 promise-2.3 protobuf-3.20.3 tensorflow-metadata-1.14.0 tensorflow_datasets-4.9.4 toml-0.10.2 tqdm-4.66.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_datasets --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b58f0be6-8d62-42a4-8632-d9ee2638f4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_485/952184717.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-04-11 09:34:14.712619: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 09:34:14.759104: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-11 09:34:14.759148: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-11 09:34:14.761928: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-11 09:34:14.773860: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 09:34:14.774998: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 09:34:18.315838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pathlib import Path\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f84642-cfd8-4324-854b-f33f05a5dff9",
   "metadata": {},
   "source": [
    "#### Loading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b56b58-724b-4e7f-96be-df0d02e432ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(\"data_all_modified-cnn-split/train\")\n",
    "    shutil.rmtree(\"data_all_modified-cnn-split/test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf501608-7bc5-4f02-a270-9d959caab98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data_all_modified-cnn-split/train/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data_all_modified-cnn-split/train/no_damage\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Path(\"data_all_modified-cnn-split/test/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data_all_modified-cnn-split/test/no_damage\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7891e8f8-3642-4860-a3a2-2940f59be0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_damage_file_paths = os.listdir('data_all_modified/damage')\n",
    "all_no_damage_file_paths = os.listdir('data_all_modified/no_damage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f20d6d87-7323-42a0-9865-3cc4093e4f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train damage image count:  11336\n",
      "test damage image count:  2834\n",
      "len of overlap:  0\n",
      "train no damage image count:  5721\n",
      "test no damage image count:  1431\n",
      "len of overlap:  0\n"
     ]
    }
   ],
   "source": [
    "train_damage_paths = random.sample(all_damage_file_paths, int(len(all_damage_file_paths)*0.8))\n",
    "print(\"train damage image count: \", len(train_damage_paths))\n",
    "test_damage_paths = [ p for p in all_damage_file_paths if p not in train_damage_paths]\n",
    "print(\"test damage image count: \", len(test_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_damage_paths if p in test_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))\n",
    "\n",
    "train_no_damage_paths = random.sample(all_no_damage_file_paths, int(len(all_no_damage_file_paths)*0.8))\n",
    "print(\"train no damage image count: \", len(train_no_damage_paths))\n",
    "test_no_damage_paths = [ p for p in all_no_damage_file_paths if p not in train_no_damage_paths]\n",
    "print(\"test no damage image count: \", len(test_no_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_no_damage_paths if p in test_no_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13040994-3ef9-427a-b31a-9a91ef8ba26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in train/damage:  11336\n",
      "Files in train/no_damage:  5721\n",
      "Files in test/damage:  2834\n",
      "Files in test/no_damage:  1431\n"
     ]
    }
   ],
   "source": [
    "# ensure to copy the images to the directories\n",
    "for p in train_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/damage', p), os.path.join('data_all_modified-cnn-split/train/damage', p) )\n",
    "\n",
    "for p in test_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/damage', p), os.path.join('data_all_modified-cnn-split/test/damage', p) )\n",
    "\n",
    "for p in train_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/no_damage', p), os.path.join('data_all_modified-cnn-split/train/no_damage', p) )\n",
    "\n",
    "for p in test_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/no_damage', p), os.path.join('data_all_modified-cnn-split/test/no_damage', p) )\n",
    "\n",
    "# check counts:\n",
    "print(\"Files in train/damage: \", len(os.listdir(\"data_all_modified-cnn-split/train/damage\")))\n",
    "print(\"Files in train/no_damage: \", len(os.listdir(\"data_all_modified-cnn-split/train/no_damage\")))\n",
    "print(\"Files in test/damage: \", len(os.listdir(\"data_all_modified-cnn-split/test/damage\")))\n",
    "print(\"Files in test/no_damage: \", len(os.listdir(\"data_all_modified-cnn-split/test/no_damage\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61b1b3-a909-4d12-98f3-b58798ead759",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37f994a7-1ce5-4bf1-af50-1609c9c324a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7152 images with dimensions 128x128\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Path to the directory containing your images\n",
    "dataset_dir = 'data_all_modified/no_damage'\n",
    "\n",
    "image_dimensions = {}\n",
    "\n",
    "# Loop through each image file in the directory\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith('.jpeg') or filename.endswith('.png'):  # Adjust file extensions as needed\n",
    "        # Open the image using PIL\n",
    "        img = Image.open(os.path.join(dataset_dir, filename))\n",
    "        # Get the dimensions of the image\n",
    "        width, height = img.size\n",
    "        # Add dimensions to the dictionary\n",
    "        if (width, height) in image_dimensions:\n",
    "            image_dimensions[(width, height)] += 1\n",
    "        else:\n",
    "            image_dimensions[(width, height)] = 1\n",
    "\n",
    "# Print summary of image dimensions\n",
    "for dimensions, count in image_dimensions.items():\n",
    "    print(f\"{count} images with dimensions {dimensions[0]}x{dimensions[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66a77897-c056-4bde-b3e1-d571baa148d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17057 files belonging to 2 classes.\n",
      "Using 13646 files for training.\n",
      "Using 3411 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = 'data_all_modified-cnn-split/train'\n",
    "batch_size = 32\n",
    "# target image size\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# note that subset=\"training\", \"validation\", \"both\", and dictates which dataset is returned\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "train_data_dir,\n",
    "validation_split=0.2,\n",
    "subset=\"both\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=batch_size\n",
    ")\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "train_rescale_ds = train_ds.map(lambda image,label:(rescale(image),label))\n",
    "val_rescale_ds = val_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c671c9-48ec-4ae7-a231-8c47e2d9167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4265 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_dir = 'data_all_modified-cnn-split/test/'\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# note that subset=\"training\", \"validation\", \"both\", and dictates what is returned\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "test_data_dir,\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    ")\n",
    "\n",
    "# approach 1: manually rescale data --\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "test_rescale_ds = test_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde4d3a-9313-477b-9954-01b2f32c6211",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899295bf-ead7-441b-bf30-5e41cf34f144",
   "metadata": {},
   "source": [
    "#### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cacd882-5a7a-4362-a0aa-87debe2b4156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 49152)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               25166336  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25338881 (96.66 MB)\n",
      "Trainable params: 25338881 (96.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model_ann = models.Sequential()\n",
    "\n",
    "# Adjust the input_shape to match the actual image size\n",
    "model_ann.add(layers.Flatten(input_shape=(128, 128, 3)))  # This line is changed\n",
    "\n",
    "model_ann.add(layers.Dense(512, activation='relu'))\n",
    "model_ann.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "# Add additional hidden layers\n",
    "model_ann.add(layers.Dense(128, activation='relu'))\n",
    "model_ann.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model_ann.add(layers.Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "model_ann.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model_ann.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f036567d-11f8-4fd5-9516-18b4da8d8f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "427/427 [==============================] - 58s 133ms/step - loss: 0.9443 - accuracy: 0.6463 - val_loss: 0.8573 - val_accuracy: 0.4057\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 63s 147ms/step - loss: 0.6070 - accuracy: 0.6843 - val_loss: 0.5802 - val_accuracy: 0.6869\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 66s 155ms/step - loss: 0.5930 - accuracy: 0.6966 - val_loss: 0.5729 - val_accuracy: 0.6740\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 64s 150ms/step - loss: 0.6272 - accuracy: 0.6612 - val_loss: 0.6350 - val_accuracy: 0.6681\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 65s 152ms/step - loss: 0.6376 - accuracy: 0.6637 - val_loss: 0.6363 - val_accuracy: 0.6681\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 63s 148ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 68s 159ms/step - loss: 0.6391 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 71s 167ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6357 - val_accuracy: 0.6681\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 63s 148ms/step - loss: 0.6387 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 61s 142ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 61s 143ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6335 - val_accuracy: 0.6681\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 62s 145ms/step - loss: 0.6390 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 67s 158ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6361 - val_accuracy: 0.6681\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 65s 151ms/step - loss: 0.6393 - accuracy: 0.6637 - val_loss: 0.6367 - val_accuracy: 0.6681\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 67s 157ms/step - loss: 0.6390 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 66s 155ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 67s 157ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 64s 150ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6360 - val_accuracy: 0.6681\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 65s 152ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 64s 150ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n"
     ]
    }
   ],
   "source": [
    "history_ann = model_ann.fit(\n",
    "    train_rescale_ds,\n",
    "    epochs=20,\n",
    "    validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "365d9347-6eaf-4709-8b93-517adb9c4525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6381585597991943\n",
      "Test Accuracy: 0.6644783020019531\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_ann.evaluate(test_rescale_ds, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8dc254c-a211-4ef3-99a8-19b23db4c99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom pathlib import Path\\nfrom tensorflow.keras.models import load_model\\n\\n# Define the path where you want to save the model\\nmodel_path = Path('./models/ANN_Model.h5')\\n\\n# Check if the file already exists\\nif model_path.exists():\\n    # If the file exists, remove it\\n    model_path.unlink()\\n\\n# Save the model\\nmodel_ann.save(model_path)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define the path where you want to save the model\n",
    "model_path = Path('./models/ANN_Model.h5')\n",
    "\n",
    "# Check if the file already exists\n",
    "if model_path.exists():\n",
    "    # If the file exists, remove it\n",
    "    model_path.unlink()\n",
    "\n",
    "# Save the model\n",
    "model_ann.save(model_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c10fa7-30e6-4cf2-95ff-5ea387fdd3c8",
   "metadata": {},
   "source": [
    "#### LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdcc722f-6d9f-413d-bd36-67eb198a37bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 126, 126, 6)       168       \n",
      "                                                                 \n",
      " average_pooling2d_2 (Avera  (None, 63, 63, 6)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 61, 61, 16)        880       \n",
      "                                                                 \n",
      " average_pooling2d_3 (Avera  (None, 30, 30, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 14400)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 120)               1728120   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1739417 (6.64 MB)\n",
      "Trainable params: 1739417 (6.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "\n",
    "model_lenet5 = models.Sequential()\n",
    "\n",
    "# Layer 1: Convolutional layer with 6 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(128,128,3)))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2: Convolutional layer with 16 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps to feed into fully connected layers\n",
    "model_lenet5.add(layers.Flatten())\n",
    "\n",
    "# Layer 3: Fully connected layer with 120 neurons\n",
    "model_lenet5.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "# Layer 4: Fully connected layer with 84 neurons\n",
    "model_lenet5.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "# Output layer: Fully connected layer with num_classes neurons\n",
    "model_lenet5.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model_lenet5.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model_lenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "484aa47b-f816-4865-a69a-6023ccd47530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "427/427 [==============================] - 25s 57ms/step - loss: 0.5697 - accuracy: 0.7219 - val_loss: 0.4680 - val_accuracy: 0.7960\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 24s 56ms/step - loss: 0.4533 - accuracy: 0.8088 - val_loss: 0.4200 - val_accuracy: 0.8118\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 24s 56ms/step - loss: 0.4109 - accuracy: 0.8323 - val_loss: 0.4264 - val_accuracy: 0.8434\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 25s 57ms/step - loss: 0.3901 - accuracy: 0.8481 - val_loss: 0.5452 - val_accuracy: 0.7593\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 25s 58ms/step - loss: 0.3709 - accuracy: 0.8605 - val_loss: 0.4349 - val_accuracy: 0.8317\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 25s 58ms/step - loss: 0.3476 - accuracy: 0.8719 - val_loss: 0.3566 - val_accuracy: 0.8563\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 25s 58ms/step - loss: 0.3219 - accuracy: 0.8811 - val_loss: 0.3176 - val_accuracy: 0.8760\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 24s 55ms/step - loss: 0.2939 - accuracy: 0.8892 - val_loss: 0.4352 - val_accuracy: 0.8103\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 22s 52ms/step - loss: 0.2704 - accuracy: 0.9019 - val_loss: 0.2928 - val_accuracy: 0.8830\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 24s 57ms/step - loss: 0.2447 - accuracy: 0.9073 - val_loss: 0.3255 - val_accuracy: 0.8707\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 24s 57ms/step - loss: 0.2262 - accuracy: 0.9142 - val_loss: 0.2281 - val_accuracy: 0.9115\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 24s 57ms/step - loss: 0.2092 - accuracy: 0.9209 - val_loss: 0.2057 - val_accuracy: 0.9226\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 24s 56ms/step - loss: 0.1943 - accuracy: 0.9266 - val_loss: 0.2038 - val_accuracy: 0.9206\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 24s 57ms/step - loss: 0.1830 - accuracy: 0.9294 - val_loss: 0.1993 - val_accuracy: 0.9203\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 24s 57ms/step - loss: 0.1730 - accuracy: 0.9349 - val_loss: 0.2075 - val_accuracy: 0.9229\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 24s 57ms/step - loss: 0.1637 - accuracy: 0.9374 - val_loss: 0.1824 - val_accuracy: 0.9285\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 24s 57ms/step - loss: 0.1548 - accuracy: 0.9402 - val_loss: 0.1791 - val_accuracy: 0.9293\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 25s 58ms/step - loss: 0.1456 - accuracy: 0.9431 - val_loss: 0.3702 - val_accuracy: 0.8490\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 25s 58ms/step - loss: 0.1355 - accuracy: 0.9490 - val_loss: 0.4154 - val_accuracy: 0.8197\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.1310 - accuracy: 0.9468 - val_loss: 0.3170 - val_accuracy: 0.8687\n"
     ]
    }
   ],
   "source": [
    "#fit the model from image generator\n",
    "history = model_lenet5.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=20,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa118d50-827a-4d65-a150-62bad73e2e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.322668194770813\n",
      "Test Accuracy: 0.8590855598449707\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_lenet5.evaluate(test_rescale_ds, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a245e-e177-4c16-816a-1260b125bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define the path where you want to save the model\n",
    "model_path = Path('./models/Lenet5_cnn.h5')\n",
    "\n",
    "# Check if the file already exists\n",
    "if model_path.exists():\n",
    "    # If the file exists, remove it\n",
    "    model_path.unlink()\n",
    "\n",
    "# Save the model\n",
    "model_lenet5.save(model_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc92eaf1-712b-4310-858b-8e3cfacd8036",
   "metadata": {},
   "source": [
    "#### Alternate-Lenet-5 CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9644fbe-637c-49be-8d16-5c439801594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 512)               2359808   \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2601153 (9.92 MB)\n",
      "Trainable params: 2601153 (9.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "from keras.regularizers import l2\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32,(3,3), activation = 'relu', input_shape = (128,128,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(512, activation = 'relu', kernel_regularizer = l2(1e-4)))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "#compile the model with RMSprob with learning rate\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(learning_rate=1e-4), metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "481b8d1e-d0b0-4108-8316-384fa294408e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "427/427 [==============================] - 94s 216ms/step - loss: 0.6522 - accuracy: 0.7271 - val_loss: 0.5141 - val_accuracy: 0.8006\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 88s 205ms/step - loss: 0.4984 - accuracy: 0.8232 - val_loss: 0.4483 - val_accuracy: 0.8631\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 91s 213ms/step - loss: 0.4226 - accuracy: 0.8608 - val_loss: 0.3538 - val_accuracy: 0.8986\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 90s 210ms/step - loss: 0.3506 - accuracy: 0.8925 - val_loss: 0.4038 - val_accuracy: 0.8666\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 92s 214ms/step - loss: 0.2895 - accuracy: 0.9147 - val_loss: 0.3177 - val_accuracy: 0.9088\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 92s 216ms/step - loss: 0.2494 - accuracy: 0.9299 - val_loss: 0.2747 - val_accuracy: 0.9323\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 95s 222ms/step - loss: 0.2234 - accuracy: 0.9384 - val_loss: 0.4504 - val_accuracy: 0.8244\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 94s 220ms/step - loss: 0.2091 - accuracy: 0.9449 - val_loss: 0.1953 - val_accuracy: 0.9493\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 91s 213ms/step - loss: 0.1909 - accuracy: 0.9508 - val_loss: 0.2244 - val_accuracy: 0.9358\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 93s 217ms/step - loss: 0.1809 - accuracy: 0.9530 - val_loss: 0.2168 - val_accuracy: 0.9402\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 89s 207ms/step - loss: 0.1735 - accuracy: 0.9554 - val_loss: 0.1570 - val_accuracy: 0.9592\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 90s 210ms/step - loss: 0.1658 - accuracy: 0.9579 - val_loss: 0.1505 - val_accuracy: 0.9610\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 91s 213ms/step - loss: 0.1576 - accuracy: 0.9589 - val_loss: 0.1464 - val_accuracy: 0.9628\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 93s 217ms/step - loss: 0.1493 - accuracy: 0.9617 - val_loss: 0.1612 - val_accuracy: 0.9592\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 101s 237ms/step - loss: 0.1460 - accuracy: 0.9637 - val_loss: 0.1621 - val_accuracy: 0.9557\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 99s 232ms/step - loss: 0.1364 - accuracy: 0.9664 - val_loss: 0.2206 - val_accuracy: 0.9405\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 110s 257ms/step - loss: 0.1336 - accuracy: 0.9671 - val_loss: 0.1393 - val_accuracy: 0.9648\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 101s 237ms/step - loss: 0.1271 - accuracy: 0.9679 - val_loss: 0.1262 - val_accuracy: 0.9686\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 94s 221ms/step - loss: 0.1237 - accuracy: 0.9694 - val_loss: 0.1241 - val_accuracy: 0.9692\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 95s 223ms/step - loss: 0.1192 - accuracy: 0.9707 - val_loss: 0.1138 - val_accuracy: 0.9721\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=20,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d75e3ba-943b-47a7-beeb-a10efa21276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.11340105533599854\n",
      "Test Accuracy: 0.9716295599937439\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_rescale_ds, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d292ee7-cc7e-4c91-864a-0b0fe67972db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define the path where you want to save the model\n",
    "model_path = Path('./models/Alternate_Lenet5.h5')\n",
    "\n",
    "# Check if the file already exists\n",
    "if model_path.exists():\n",
    "    # If the file exists, remove it\n",
    "    model_path.unlink()\n",
    "\n",
    "# Save the model\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44397e71-a1fb-4d8d-9333-426d2e706570",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/Alternate_Lenet5.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f692de23-daa5-4c89-bda5-250a233daf34",
   "metadata": {},
   "source": [
    "## For testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24151092-56b3-4ad3-9017-2f088c8fe1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 152ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'probability_no_damage': 0.00027020028210245073, 'prediction': 'Damage'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('./models/Alternate_Lenet5.keras')\n",
    "\n",
    "# Read the image file from the request\n",
    "img_file = './data_all_modified-cnn-split/test/damage/-95.588835_29.769012.jpeg'\n",
    "\n",
    "# Open the image using PIL\n",
    "img = Image.open(img_file)\n",
    "        \n",
    "# Resize and preprocess the image\n",
    "img = img.resize((128, 128))\n",
    "img_array = np.array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Perform inference using the pre-trained model\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "# Extract the probability of being damaged\n",
    "probability_damaged = prediction[0][0]\n",
    "\n",
    "# Determine the class based on the threshold\n",
    "threshold = 0.5\n",
    "if probability_damaged >= threshold:\n",
    "    prediction_label = 'No Damage'\n",
    "else:\n",
    "    prediction_label = 'Damage'\n",
    "\n",
    "# Convert the prediction result into a JSON format\n",
    "result = {\n",
    "    'probability_no_damage': float(probability_damaged),\n",
    "    'prediction': prediction_label\n",
    "}\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f85e379-450b-42ff-b233-da803adbb594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['damage', 'no_damage']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "719863aa-5c29-4fd3-8ab5-ead5e3828da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0002702]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
