{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2938918b-ec01-4ef9-a0e2-e018038d2965",
   "metadata": {},
   "source": [
    "# Project 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ce3b18-c0f4-40a5-991d-f08c5f48f851",
   "metadata": {},
   "source": [
    "#### Jason Kim \n",
    "#### Braulio Lopez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729fbe8-e7e4-4608-9f91-654aca7fa9ad",
   "metadata": {},
   "source": [
    "### Part 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66736b9-cd39-4a22-b85a-25e5d1cba3d2",
   "metadata": {},
   "source": [
    "#### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4e1004-3a64-45ce-811e-56df55181d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.4-py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m270.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m279.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting etils[enp,epath,etree]>=0.9.0\n",
      "  Downloading etils-1.8.0-py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.1/156.1 kB\u001b[0m \u001b[31m278.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (1.26.3)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (4.23.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (5.9.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.31.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.4.0)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m233.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Collecting array-record>=0.5.0\n",
      "  Downloading array_record-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m139.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m287.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting importlib_resources\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.9.0)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2023.11.17)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m252.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m291.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.20\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m285.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21483 sha256=c3780ef5ee668370465b56f040f84567770c6c1d6a91b89e8d3a755739c7d33c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7i3cr0z8/wheels/74/05/89/d0909dd6ebad0a26f2b4dcb2499b1d65999c5b6ed416be7f85\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, tqdm, toml, protobuf, promise, importlib_resources, fsspec, etils, click, absl-py, googleapis-common-protos, tensorflow-metadata, array-record, tensorflow_datasets\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tfds is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 array-record-0.5.1 click-8.1.7 dm-tree-0.1.8 etils-1.8.0 fsspec-2024.3.1 googleapis-common-protos-1.63.0 importlib_resources-6.4.0 promise-2.3 protobuf-3.20.3 tensorflow-metadata-1.14.0 tensorflow_datasets-4.9.4 toml-0.10.2 tqdm-4.66.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_datasets --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b58f0be6-8d62-42a4-8632-d9ee2638f4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104/952184717.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-04-11 01:25:01.045327: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 01:25:01.095864: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-11 01:25:01.095902: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-11 01:25:01.098747: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-11 01:25:01.110974: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 01:25:01.111827: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 01:25:04.696508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pathlib import Path\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f84642-cfd8-4324-854b-f33f05a5dff9",
   "metadata": {},
   "source": [
    "#### Loading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b56b58-724b-4e7f-96be-df0d02e432ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(\"data_all_modified-cnn-split/train\")\n",
    "    shutil.rmtree(\"data_all_modified-cnn-split/test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd19865-f518-4998-a7fc-a6160da76b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf501608-7bc5-4f02-a270-9d959caab98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data_all_modified-cnn-split/train/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data_all_modified-cnn-split/train/no_damage\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Path(\"data_all_modified-cnn-split/test/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data_all_modified-cnn-split/test/no_damage\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7891e8f8-3642-4860-a3a2-2940f59be0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_damage_file_paths = os.listdir('data_all_modified/damage')\n",
    "all_no_damage_file_paths = os.listdir('data_all_modified/no_damage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f20d6d87-7323-42a0-9865-3cc4093e4f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train damage image count:  11336\n",
      "test damage image count:  2834\n",
      "len of overlap:  0\n",
      "train no damage image count:  5721\n",
      "test no damage image count:  1431\n",
      "len of overlap:  0\n"
     ]
    }
   ],
   "source": [
    "train_damage_paths = random.sample(all_damage_file_paths, int(len(all_damage_file_paths)*0.8))\n",
    "print(\"train damage image count: \", len(train_damage_paths))\n",
    "test_damage_paths = [ p for p in all_damage_file_paths if p not in train_damage_paths]\n",
    "print(\"test damage image count: \", len(test_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_damage_paths if p in test_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))\n",
    "\n",
    "train_no_damage_paths = random.sample(all_no_damage_file_paths, int(len(all_no_damage_file_paths)*0.8))\n",
    "print(\"train no damage image count: \", len(train_no_damage_paths))\n",
    "test_no_damage_paths = [ p for p in all_no_damage_file_paths if p not in train_no_damage_paths]\n",
    "print(\"test no damage image count: \", len(test_no_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_no_damage_paths if p in test_no_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13040994-3ef9-427a-b31a-9a91ef8ba26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in train/damage:  11336\n",
      "Files in train/no_damage:  5721\n",
      "Files in test/damage:  2834\n",
      "Files in test/no_damage:  1431\n"
     ]
    }
   ],
   "source": [
    "# ensure to copy the images to the directories\n",
    "for p in train_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/damage', p), os.path.join('data_all_modified-cnn-split/train/damage', p) )\n",
    "\n",
    "for p in test_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/damage', p), os.path.join('data_all_modified-cnn-split/test/damage', p) )\n",
    "\n",
    "for p in train_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/no_damage', p), os.path.join('data_all_modified-cnn-split/train/no_damage', p) )\n",
    "\n",
    "for p in test_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/no_damage', p), os.path.join('data_all_modified-cnn-split/test/no_damage', p) )\n",
    "\n",
    "# check counts:\n",
    "print(\"Files in train/damage: \", len(os.listdir(\"data_all_modified-cnn-split/train/damage\")))\n",
    "print(\"Files in train/no_damage: \", len(os.listdir(\"data_all_modified-cnn-split/train/no_damage\")))\n",
    "print(\"Files in test/damage: \", len(os.listdir(\"data_all_modified-cnn-split/test/damage\")))\n",
    "print(\"Files in test/no_damage: \", len(os.listdir(\"data_all_modified-cnn-split/test/no_damage\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61b1b3-a909-4d12-98f3-b58798ead759",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37f994a7-1ce5-4bf1-af50-1609c9c324a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7152 images with dimensions 128x128\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Path to the directory containing your images\n",
    "dataset_dir = 'data_all_modified/no_damage'\n",
    "\n",
    "image_dimensions = {}\n",
    "\n",
    "# Loop through each image file in the directory\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith('.jpeg') or filename.endswith('.png'):  # Adjust file extensions as needed\n",
    "        # Open the image using PIL\n",
    "        img = Image.open(os.path.join(dataset_dir, filename))\n",
    "        # Get the dimensions of the image\n",
    "        width, height = img.size\n",
    "        # Add dimensions to the dictionary\n",
    "        if (width, height) in image_dimensions:\n",
    "            image_dimensions[(width, height)] += 1\n",
    "        else:\n",
    "            image_dimensions[(width, height)] = 1\n",
    "\n",
    "# Print summary of image dimensions\n",
    "for dimensions, count in image_dimensions.items():\n",
    "    print(f\"{count} images with dimensions {dimensions[0]}x{dimensions[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66a77897-c056-4bde-b3e1-d571baa148d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17057 files belonging to 2 classes.\n",
      "Using 13646 files for training.\n",
      "Using 3411 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = 'data_all_modified-cnn-split/train'\n",
    "batch_size = 32\n",
    "# target image size\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# note that subset=\"training\", \"validation\", \"both\", and dictates which dataset is returned\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "train_data_dir,\n",
    "validation_split=0.2,\n",
    "subset=\"both\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=batch_size\n",
    ")\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "train_rescale_ds = train_ds.map(lambda image,label:(rescale(image),label))\n",
    "val_rescale_ds = val_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c671c9-48ec-4ae7-a231-8c47e2d9167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4265 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_dir = 'data_all_modified-cnn-split/test/'\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "# this is what was used in the paper --\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# note that subset=\"training\", \"validation\", \"both\", and dictates what is returned\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "test_data_dir,\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    ")\n",
    "\n",
    "# approach 1: manually rescale data --\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "test_rescale_ds = test_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf9379-dbda-49b8-aeae-9e4a3ef10b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde4d3a-9313-477b-9954-01b2f32c6211",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899295bf-ead7-441b-bf30-5e41cf34f144",
   "metadata": {},
   "source": [
    "#### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cacd882-5a7a-4362-a0aa-87debe2b4156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model_ann = models.Sequential()\n",
    "\n",
    "# Adjust the input_shape to match the actual image size\n",
    "model_ann.add(layers.Flatten(input_shape=(128, 128, 3)))  # This line is changed\n",
    "\n",
    "model_ann.add(layers.Dense(512, activation='relu'))\n",
    "model_ann.add(layers.Dropout(0.5))  # Optional: Helps prevent overfitting\n",
    "model_ann.add(layers.Dense(256, activation='relu'))\n",
    "model_ann.add(layers.Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "model_ann.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model_ann.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f036567d-11f8-4fd5-9516-18b4da8d8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ann = model_ann.fit(\n",
    "    train_rescale_ds,\n",
    "    epochs=1,\n",
    "    validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d9347-6eaf-4709-8b93-517adb9c4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model_ann.evaluate(test_rescale_ds, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc254c-a211-4ef3-99a8-19b23db4c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/ANN_Model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c10fa7-30e6-4cf2-95ff-5ea387fdd3c8",
   "metadata": {},
   "source": [
    "#### LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc722f-6d9f-413d-bd36-67eb198a37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "\n",
    "model_lenet5 = models.Sequential()\n",
    "\n",
    "# Layer 1: Convolutional layer with 6 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(128,128,3)))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2: Convolutional layer with 16 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps to feed into fully connected layers\n",
    "model_lenet5.add(layers.Flatten())\n",
    "\n",
    "# Layer 3: Fully connected layer with 120 neurons\n",
    "model_lenet5.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "# Layer 4: Fully connected layer with 84 neurons\n",
    "model_lenet5.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "# Output layer: Fully connected layer with num_classes neurons (e.g., 3 )\n",
    "model_lenet5.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model_lenet5.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model_lenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484aa47b-f816-4865-a69a-6023ccd47530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model from image generator\n",
    "history = model_lenet5.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=1,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa118d50-827a-4d65-a150-62bad73e2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model_lenet5.evaluate(test_rescale_ds, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a245e-e177-4c16-816a-1260b125bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/Lenet5_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc92eaf1-712b-4310-858b-8e3cfacd8036",
   "metadata": {},
   "source": [
    "#### Alternate-Lenet-5 CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9644fbe-637c-49be-8d16-5c439801594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17057 images belonging to 2 classes.\n",
      "Found 4265 images belonging to 2 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104/4210799483.py:65: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 25s 232ms/step - loss: 0.7677 - acc: 0.6350 - val_loss: 0.6993 - val_acc: 0.6731\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.5873 - acc: 0.7476 - val_loss: 0.4268 - val_acc: 0.8537\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.5150 - acc: 0.7862 - val_loss: 0.4563 - val_acc: 0.8263\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.4908 - acc: 0.8100 - val_loss: 0.3021 - val_acc: 0.9087\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.4182 - acc: 0.8466 - val_loss: 0.2896 - val_acc: 0.9125\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.3518 - acc: 0.8842 - val_loss: 0.3304 - val_acc: 0.8863\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.3323 - acc: 0.8863 - val_loss: 0.3175 - val_acc: 0.8819\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.3278 - acc: 0.8859 - val_loss: 0.1865 - val_acc: 0.9388\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.3084 - acc: 0.8925 - val_loss: 0.1871 - val_acc: 0.9369\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.2950 - acc: 0.8938 - val_loss: 0.1755 - val_acc: 0.9456\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 22s 222ms/step - loss: 0.2947 - acc: 0.8984 - val_loss: 0.2189 - val_acc: 0.9337\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.2652 - acc: 0.9053 - val_loss: 0.2059 - val_acc: 0.9319\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.2660 - acc: 0.9159 - val_loss: 0.1749 - val_acc: 0.9344\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 23s 225ms/step - loss: 0.2410 - acc: 0.9166 - val_loss: 0.2289 - val_acc: 0.9187\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.2479 - acc: 0.9194 - val_loss: 0.1875 - val_acc: 0.9406\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.2629 - acc: 0.9175 - val_loss: 0.1842 - val_acc: 0.9325\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.2508 - acc: 0.9122 - val_loss: 0.1865 - val_acc: 0.9350\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 26s 254ms/step - loss: 0.2254 - acc: 0.9253 - val_loss: 0.1653 - val_acc: 0.9463\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 0.2267 - acc: 0.9175 - val_loss: 0.1602 - val_acc: 0.9475\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.2212 - acc: 0.9233 - val_loss: 0.1613 - val_acc: 0.9456\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "from keras.regularizers import l2\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3), activation = 'relu', input_shape = (128,128,3)))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3), activation = 'relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation = 'relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation = 'relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation = 'relu', kernel_regularizer = l2(1e-4)))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "#compile the model with RMSprob with learning rate\n",
    "from keras import optimizers\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr=1e-4), metrics = ['acc'])\n",
    "\n",
    "#process the jpeg image\n",
    "#create an image generator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#train using data augmentation and dropout\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale = 1./255,\n",
    "                    rotation_range = 40,\n",
    "                    width_shift_range = 0.2,\n",
    "                    height_shift_range = 0.2,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range = 0.2,\n",
    "                    horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255) #validation data should not be augmented\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    'data_all_modified-cnn-split/train', \n",
    "                    target_size = (128,128),\n",
    "                    batch_size = 32,\n",
    "                    class_mode = 'binary')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                    'data_all_modified-cnn-split/test', \n",
    "                    target_size = (128,128),\n",
    "                    batch_size = 32,\n",
    "                    class_mode = 'binary')\n",
    "\n",
    "#fit the model from image generator\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=100,\n",
    "            epochs=20,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d75e3ba-943b-47a7-beeb-a10efa21276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.15750761330127716\n",
      "Test Accuracy: 0.9418522715568542\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_rescale_ds, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d292ee7-cc7e-4c91-864a-0b0fe67972db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define the path where you want to save the model\n",
    "model_path = Path('./models/Alternate_Lenet5.h5')\n",
    "\n",
    "# Check if the file already exists\n",
    "if model_path.exists():\n",
    "    # If the file exists, remove it\n",
    "    model_path.unlink()\n",
    "\n",
    "# Save the model\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24151092-56b3-4ad3-9017-2f088c8fe1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'probability_no_damage': 0.9806310534477234, 'prediction': 'No Damage'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('./models/Alternate_Lenet5.keras')\n",
    "\n",
    "# Read the image file from the request\n",
    "img_file = './data_all_modified-cnn-split/test/no_damage/-95.63744_29.771631.jpeg'\n",
    "\n",
    "# Open the image using PIL\n",
    "img = Image.open(img_file)\n",
    "        \n",
    "# Resize and preprocess the image\n",
    "img = img.resize((128, 128))\n",
    "img_array = np.array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Perform inference using the pre-trained model\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "# Extract the probability of being damaged\n",
    "probability_damaged = prediction[0][0]\n",
    "\n",
    "# Determine the class based on the threshold\n",
    "threshold = 0.5\n",
    "if probability_damaged >= threshold:\n",
    "    prediction_label = 'No Damage'\n",
    "else:\n",
    "    prediction_label = 'Damage'\n",
    "\n",
    "# Convert the prediction result into a JSON format\n",
    "result = {\n",
    "    'probability_no_damage': float(probability_damaged),\n",
    "    'prediction': prediction_label\n",
    "}\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f85e379-450b-42ff-b233-da803adbb594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00093209]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a666fcae-4af3-4330-a735-e2202603eb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00093208795"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98a2e1-9da4-43e7-a049-749646f96b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
